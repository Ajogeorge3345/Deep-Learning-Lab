import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM, Input
from sklearn.metrics import r2_score, mean_absolute_error

# Step 1: Load the data
data = pd.read_csv("nifty.csv", index_col="Date", parse_dates=True)

# Normalize the numerical columns
scaler = MinMaxScaler()
data[['Open', 'High', 'Low', 'Close']] = scaler.fit_transform(data[['Open', 'High', 'Low', 'Close']])

# Use previous 'n' days' data to predict the next day's 'Close' price
look_back = 10  # Number of days to look back

def create_lagged_features(data, look_back):
    X, y = [], []
    for i in range(len(data) - look_back):
        X.append(data[['Open', 'High', 'Low', 'Close']].iloc[i:i + look_back].values)
        y.append(data['Close'].iloc[i + look_back])
    return np.array(X), np.array(y)

# Generate lagged data
X, y = create_lagged_features(data, look_back)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

model = tf.keras.Sequential([
    LSTM(64, input_shape=(look_back, 4)),  # LSTM layer to handle 3D input
    Dense(32, activation='relu'),
    Dense(1, activation='linear')
])

model.compile(loss='mse', optimizer='adam')
model.fit(X_train, y_train, epochs=70, verbose=1)
y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
print(f"Mean Absolute Error: {mae:.4f}")

# Step 8: Visualize the results
plt.figure(figsize=(10, 4))
plt.plot(y_test, label='Actual Close Price')
plt.plot(y_pred, label='Predicted Close Price')
plt.title('Actual vs Predicted Close Prices')
plt.xlabel('Days')
plt.ylabel('Normalized Close Price')
plt.legend()
plt.show()
